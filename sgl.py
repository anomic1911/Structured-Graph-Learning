# -*- coding: utf-8 -*-
"""SGL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qUm56x4GCuLb4Zbgr0yM1r_PXpoY1TvT
"""

import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons, make_blobs
from learn_graph_topology import learn_k_component_graph

np.random.seed(0)
n = 50  # number of nodes per cluster
k = 2   # number of components
X, y = make_moons(n_samples=n*k, noise=.05, shuffle=True)
# dict to store position of nodes
pos = {}
for i in range(n*k):
    pos[i] = X[i]
# Visualization of original data
plt.scatter(X[:,0], X[:,1], c=y )
plt.show()
# X, y = make_blobs(n_samples=n*k, centers=k, n_features=2, random_state=0)

# compute sample correlation matrix
S = np.dot(X, X.T)

# estimate underlying graph
graph = learn_k_component_graph(S, k=2, maxiter=1000, record_objective = True, beta=0.1, record_weights = True)

NLL = graph['negloglike']
print('NLL: ', min(NLL))
OBJ = graph['obj_fun']
print('Objective: ', min(OBJ))

# build network
A = graph['adjacency']
G = nx.from_numpy_matrix(A)
# Graph statistics
print('Nodes: ', G.number_of_nodes(), 'Edges: ', G.number_of_edges() )

# normalize edge weights to plot nice graph
all_weights = []
for (node1,node2,data) in G.edges(data=True):
    all_weights.append(data['weight'])
max_weight = max(all_weights)
norm_weights = [3* w / max_weight for w in all_weights]
norm_weights = norm_weights
print(norm_weights)

plt.figure(1,figsize=(18,18)) 
nx.draw_networkx(G,pos, width=norm_weights)
plt.show()

